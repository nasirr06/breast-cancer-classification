{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../BreaKHis_v1/histology_slides/breast/'\n",
    "data_path = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(file_dir):\n",
    "    files = os.listdir(file_dir)\n",
    "    for file in files:\n",
    "        if os.path.isdir(file_dir+file):\n",
    "            if file not in ['40X', '100X', '200X', '400X']:\n",
    "                transform(file_dir+file+'/')\n",
    "            else:\n",
    "                filePTH = file_dir+file + '/'\n",
    "                images = os.listdir(filePTH)\n",
    "                for _img in images:\n",
    "                    img_path = filePTH+_img\n",
    "                    if _img[4]=='B':\n",
    "                        with open(data_path+file+'/benign.txt', 'a+') as myfile:\n",
    "                            myfile.write(img_path+'\\n')\n",
    "                    else:\n",
    "                        with open(data_path+file+'/malignant.txt', 'a+') as myfile:\n",
    "                            myfile.write(img_path+'\\n')\n",
    "\n",
    "#transform(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(filePath, size=500):\n",
    "    f = open(filePath, 'r')\n",
    "    paths = np.array([path[:-1] for path in f.readlines()])\n",
    "    print(\"Total samples: {}\".format(len(paths)))\n",
    "    valid = np.random.choice(len(paths), size, replace=False) # Training samples\n",
    "    rem = [i for i in range(len(paths)) if i not in valid]    # Validation samples\n",
    "    if len(rem) > 100:\n",
    "        rem = np.random.choice(rem, 100, replace=False)\n",
    "    return paths[valid], paths[rem]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 625\n",
      "Total samples: 1370\n",
      "40X: Training Size: 1000, Validation Size: 200\n"
     ]
    }
   ],
   "source": [
    "# 40X\n",
    "b_train, b_val = sample(\"../data/40X/benign.txt\")\n",
    "bl_train, bl_val = np.zeros(b_train.shape), np.zeros(b_val.shape)\n",
    "b_train = np.concatenate((b_train.reshape((-1, 1)), bl_train.reshape(-1, 1)), axis=1)\n",
    "b_val = np.concatenate((b_val.reshape((-1, 1)), bl_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "m_train, m_val = sample(\"../data/40X/malignant.txt\")\n",
    "mt_label, mt_val = np.ones(m_train.shape), np.ones(m_val.shape)\n",
    "m_train = np.concatenate((m_train.reshape((-1, 1)), mt_label.reshape(-1, 1)), axis=1)\n",
    "m_val = np.concatenate((m_val.reshape((-1, 1)), mt_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "train_40X, val_40X = np.vstack((b_train, m_train)), np.vstack((b_val, m_val))\n",
    "print(\"40X: Training Size: {}, Validation Size: {}\".format(len(train_40X), len(val_40X)))\n",
    "\n",
    "# Storing in the pickle file\n",
    "train_file, val_file = open(\"../data/40X/train.pickle\", \"wb\"), open(\"../data/40X/val.pickle\", \"wb\")\n",
    "pickle.dump(train_40X, train_file)\n",
    "pickle.dump(val_40X, val_file)\n",
    "train_file.close()\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 644\n",
      "Total samples: 1437\n",
      "40X: Training Size: 1000, Validation Size: 200\n"
     ]
    }
   ],
   "source": [
    "# 100X\n",
    "b_train, b_val = sample(\"../data/100X/benign.txt\")\n",
    "bl_train, bl_val = np.zeros(b_train.shape), np.zeros(b_val.shape)\n",
    "b_train = np.concatenate((b_train.reshape((-1, 1)), bl_train.reshape(-1, 1)), axis=1)\n",
    "b_val = np.concatenate((b_val.reshape((-1, 1)), bl_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "m_train, m_val = sample(\"../data/100X/malignant.txt\")\n",
    "mt_label, mt_val = np.ones(m_train.shape), np.ones(m_val.shape)\n",
    "m_train = np.concatenate((m_train.reshape((-1, 1)), mt_label.reshape(-1, 1)), axis=1)\n",
    "m_val = np.concatenate((m_val.reshape((-1, 1)), mt_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "train_100X, val_100X = np.vstack((b_train, m_train)), np.vstack((b_val, m_val))\n",
    "print(\"100X: Training Size: {}, Validation Size: {}\".format(len(train_100X), len(val_100X)))\n",
    "\n",
    "# Storing in the pickle file\n",
    "train_file, val_file = open(\"../data/100X/train.pickle\", \"wb\"), open(\"../data/100X/val.pickle\", \"wb\")\n",
    "pickle.dump(train_100X, train_file)\n",
    "pickle.dump(val_100X, val_file)\n",
    "train_file.close()\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 623\n",
      "Total samples: 1390\n",
      "200X: Training Size: 1000, Validation Size: 200\n"
     ]
    }
   ],
   "source": [
    "# 200X\n",
    "b_train, b_val = sample(\"../data/200X/benign.txt\")\n",
    "bl_train, bl_val = np.zeros(b_train.shape), np.zeros(b_val.shape)\n",
    "b_train = np.concatenate((b_train.reshape((-1, 1)), bl_train.reshape(-1, 1)), axis=1)\n",
    "b_val = np.concatenate((b_val.reshape((-1, 1)), bl_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "m_train, m_val = sample(\"../data/200X/malignant.txt\")\n",
    "mt_label, mt_val = np.ones(m_train.shape), np.ones(m_val.shape)\n",
    "m_train = np.concatenate((m_train.reshape((-1, 1)), mt_label.reshape(-1, 1)), axis=1)\n",
    "m_val = np.concatenate((m_val.reshape((-1, 1)), mt_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "train_200X, val_200X = np.vstack((b_train, m_train)), np.vstack((b_val, m_val))\n",
    "print(\"200X: Training Size: {}, Validation Size: {}\".format(len(train_200X), len(val_200X)))\n",
    "\n",
    "# Storing in the pickle file\n",
    "train_file, val_file = open(\"../data/200X/train.pickle\", \"wb\"), open(\"../data/200X/val.pickle\", \"wb\")\n",
    "pickle.dump(train_200X, train_file)\n",
    "pickle.dump(val_200X, val_file)\n",
    "train_file.close()\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 588\n",
      "Total samples: 1232\n",
      "400X: Training Size: 1000, Validation Size: 188\n"
     ]
    }
   ],
   "source": [
    "# 400X\n",
    "b_train, b_val = sample(\"../data/400X/benign.txt\")\n",
    "bl_train, bl_val = np.zeros(b_train.shape), np.zeros(b_val.shape)\n",
    "b_train = np.concatenate((b_train.reshape((-1, 1)), bl_train.reshape(-1, 1)), axis=1)\n",
    "b_val = np.concatenate((b_val.reshape((-1, 1)), bl_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "m_train, m_val = sample(\"../data/400X/malignant.txt\")\n",
    "mt_label, mt_val = np.ones(m_train.shape), np.ones(m_val.shape)\n",
    "m_train = np.concatenate((m_train.reshape((-1, 1)), mt_label.reshape(-1, 1)), axis=1)\n",
    "m_val = np.concatenate((m_val.reshape((-1, 1)), mt_val.reshape(-1, 1)), axis=1)\n",
    "\n",
    "train_400X, val_400X = np.vstack((b_train, m_train)), np.vstack((b_val, m_val))\n",
    "print(\"400X: Training Size: {}, Validation Size: {}\".format(len(train_400X), len(val_400X)))\n",
    "\n",
    "# Storing in the pickle file\n",
    "train_file, val_file = open(\"../data/400X/train.pickle\", \"wb\"), open(\"../data/400X/val.pickle\", \"wb\")\n",
    "pickle.dump(train_40X, train_file)\n",
    "pickle.dump(val_40X, val_file)\n",
    "train_file.close()\n",
    "val_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
