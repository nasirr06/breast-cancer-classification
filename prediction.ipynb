{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchsummary import summary\n",
    "import tabulate\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.utils.data as utils\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir, mag):\n",
    "    '''\n",
    "    data_dir: Data directory containing all the extracted features\n",
    "    mag: Magnification of the images i.e. ['40X', '100X', '200X', '400X']\n",
    "    '''\n",
    "    X, y = list(), list()\n",
    "    data_path = data_dir + mag\n",
    "    for l in os.listdir(data_path):\n",
    "        xi = np.load(data_path+l)\n",
    "        yi = (l[4]=='M')\n",
    "        X.append(xi)\n",
    "        y.append(yi)\n",
    "    X, y = np.array(X), np.array(y)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/resnet/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1995"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = get_data(data_dir, '40X/')\n",
    "#X, y = get_data(data_dir, '100X/')\n",
    "#X, y = get_data(data_dir, '200X/')\n",
    "#X, y = get_data(data_dir, '400X/')\n",
    "\n",
    "data = list(zip(X, y))\n",
    "data = np.array(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (1596, 2048), (1596, 1)\n",
      "Validation Data: (267, 2048), (267, 1)\n",
      "Testing Data: (132, 2048), (132, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x, vtd_x, train_y, vtd_y = train_test_split(data[:, 0:1], data[:, 1:], test_size=0.20, random_state=42)\n",
    "val_x, test_x, val_y, test_y = train_test_split(vtd_x, vtd_y, test_size=0.33, random_state=42)\n",
    "\n",
    "train_x = np.array([np.squeeze(i[0]) for i in train_x])\n",
    "train_y = np.array([[float(i[0])] for i in train_y])\n",
    "print('Training Data: {}, {}'.format(train_x.shape, train_y.shape))\n",
    "\n",
    "val_x = np.array([np.squeeze(i[0]) for i in val_x])\n",
    "val_y = np.array([[float(i[0])] for i in val_y])\n",
    "print('Validation Data: {}, {}'.format(val_x.shape, val_y.shape))\n",
    "\n",
    "test_x = np.array([np.squeeze(i[0]) for i in test_x])\n",
    "test_y = np.array([[float(i[0])] for i in test_y])\n",
    "print('Testing Data: {}, {}'.format(test_x.shape, test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0005, 0.0010])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##################################################\n",
    "# For weighted Binary Cross Entropy\n",
    "# To apply inverse class frequency as a re-weighting\n",
    "# strategy we should have two output probabilities\n",
    "def get_weights(data):\n",
    "    sumP, sumN = 0, 0\n",
    "    for xi in data:\n",
    "        if xi:\n",
    "            sumP += 1\n",
    "        else:\n",
    "            sumN += 1\n",
    "    return torch.tensor([0.5/sumP, 0.5/sumN])\n",
    "##################################################\n",
    "weight = get_weights(train_y)\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_x = torch.stack([torch.Tensor(i) for i in train_x]) # transform to torch tensors\n",
    "t_y = torch.stack([torch.Tensor(i) for i in train_y])\n",
    "my_dataset = utils.TensorDataset(t_x,t_y) # create your datset\n",
    "train_dataloader = utils.DataLoader(my_dataset) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_x = torch.stack([torch.Tensor(i) for i in val_x]) # transform to torch tensors\n",
    "v_y = torch.stack([torch.Tensor(i) for i in val_y])\n",
    "my_dataset = utils.TensorDataset(v_x,v_y) # create your datset\n",
    "val_dataloader = utils.DataLoader(my_dataset) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_x = torch.stack([torch.Tensor(i) for i in test_x]) # transform to torch tensors\n",
    "te_y = torch.stack([torch.Tensor(i) for i in test_y])\n",
    "my_dataset = utils.TensorDataset(te_x,te_y) # create your datset\n",
    "test_dataloader = utils.DataLoader(my_dataset) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1596, 2048]),\n",
       " torch.Size([1596, 1]),\n",
       " torch.Size([267, 2048]),\n",
       " torch.Size([267, 1]),\n",
       " torch.Size([132, 2048]),\n",
       " torch.Size([132, 1]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_x.shape, t_y.shape, v_x.shape, v_y.shape, te_x.shape, te_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Architecture\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(2048, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        self.fc3 = nn.Linear(512, 64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "criterion = nn.BCELoss(weight=None)\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=0.001,\n",
    "    weight_decay=5e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Training Loss:  0.6516669427379147 Valid Loss:  0.6462739032975743\n",
      "Epoch: 2 Training Loss:  0.6451555254563216 Valid Loss:  0.6485401658752884\n",
      "Epoch: 3 Training Loss:  0.635424323038771 Valid Loss:  0.6470915210827459\n",
      "Epoch: 4 Training Loss:  0.7567313926419857 Valid Loss:  0.6495683031358969\n",
      "Epoch: 5 Training Loss:  0.8215406119371971 Valid Loss:  0.6467727295468363\n",
      "Epoch: 6 Training Loss:  0.6417773289659952 Valid Loss:  0.6465383236774345\n",
      "Epoch: 7 Training Loss:  0.7501387623427194 Valid Loss:  0.6476074102219571\n",
      "Epoch: 8 Training Loss:  0.7432385139936184 Valid Loss:  0.652194360333882\n",
      "Epoch: 9 Training Loss:  0.7373811368869618 Valid Loss:  0.6492541941364159\n",
      "Epoch: 10 Training Loss:  0.617450839893561 Valid Loss:  0.650145574343785\n",
      "Epoch: 11 Training Loss:  0.7426798149754062 Valid Loss:  0.6500865234417862\n",
      "Epoch: 12 Training Loss:  0.7836136683415438 Valid Loss:  0.649812553036079\n",
      "Epoch: 13 Training Loss:  0.7846485668700325 Valid Loss:  0.6498897022075867\n",
      "Epoch: 14 Training Loss:  0.7117986726012486 Valid Loss:  0.649367291940732\n",
      "Epoch: 15 Training Loss:  0.8577402578946489 Valid Loss:  0.6493639269571626\n",
      "Epoch: 16 Training Loss:  0.7361052200304987 Valid Loss:  3.098083231601191\n",
      "Epoch: 17 Training Loss:  0.864325096863659 Valid Loss:  0.6493639430303252\n",
      "Epoch: 18 Training Loss:  0.6622664518080267 Valid Loss:  0.6496156982045048\n",
      "Epoch: 19 Training Loss:  0.6184368674972451 Valid Loss:  0.6503079292479526\n",
      "Epoch: 20 Training Loss:  0.7262838905746533 Valid Loss:  0.6503947897350297\n",
      "Epoch: 21 Training Loss:  0.7666924876362251 Valid Loss:  0.6501027439417464\n",
      "Epoch: 22 Training Loss:  0.6862017065080598 Valid Loss:  0.6499665968873528\n",
      "Epoch: 23 Training Loss:  0.6279450838651582 Valid Loss:  0.6497172092677056\n",
      "Epoch: 24 Training Loss:  0.7404822311386088 Valid Loss:  0.6499416333682528\n",
      "Epoch: 25 Training Loss:  0.7567381902949255 Valid Loss:  0.6499303807033582\n",
      "Epoch: 26 Training Loss:  0.7217160088546097 Valid Loss:  0.6493370740601186\n",
      "Epoch: 27 Training Loss:  0.6311216647306238 Valid Loss:  0.6493498919608441\n",
      "Epoch: 28 Training Loss:  0.6205947953638128 Valid Loss:  0.6499643791257665\n",
      "Epoch: 29 Training Loss:  0.7435165726713987 Valid Loss:  0.6499203259355566\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 30): \n",
    "    train_loss, valid_loss = [], []\n",
    "    \n",
    "    model.train()\n",
    "    for data, target in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    ## evaluation part \n",
    "    model.eval()\n",
    "    for data, target in val_dataloader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss.append(loss.item())\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './trained_models/40X/resnet_transfer.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-fed2858f494d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'./trained_models/40X/resnet_transfer.pt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#torch.save(model, './trained_models/100X/resnet_transfer.pt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#torch.save(model, './trained_models/200X/resnet_transfer.pt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#torch.save(model, './trained_models/400X/resnet_transfer.pt')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \"\"\"\n\u001b[1;32m--> 224\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[1;34m(f, mode, body)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './trained_models/40X/resnet_transfer.pt'"
     ]
    }
   ],
   "source": [
    "torch.save(model, './trained_models/40X/resnet_transfer.pt')\n",
    "#torch.save(model, './trained_models/100X/resnet_transfer.pt')\n",
    "#torch.save(model, './trained_models/200X/resnet_transfer.pt')\n",
    "#torch.save(model, './trained_models/400X/resnet_transfer.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, 30): ## run the model for 10 epochs\n",
    "    train_loss, valid_loss = [], []\n",
    "    ## training part \n",
    "    model.train()\n",
    "    for data, target in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.append(loss.item())\n",
    "        \n",
    "    ## evaluation part \n",
    "    model.eval()\n",
    "    for data, target in val_dataloader:\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        valid_loss.append(loss.item())\n",
    "    print (\"Epoch:\", epoch, \"Training Loss: \", np.mean(train_loss), \"Valid Loss: \", np.mean(valid_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './trained_models/40X/resnext_transfer.pt')\n",
    "#torch.save(model, './trained_models/100X/resnext_transfer.pt')\n",
    "#torch.save(model, './trained_models/200X/resnext_transfer.pt')\n",
    "#torch.save(model, './trained_models/400X/resnext_transfer.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
